{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575001da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.50590447e-24, 3.44861937e-27, 4.65997539e-24, 8.75116818e-26,\n",
       "       2.54694442e-35, 1.07614287e-37, 1.76913590e-15, 6.62121363e-20,\n",
       "       2.57847755e-10, 1.00000000e+00])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convolution function\n",
    "def convolve2d(image, kernel, stride, padding):\n",
    "    # Add zero padding to the input image\n",
    "    image_padded = np.pad(image, [(padding, padding), (padding, padding), (0, 0)], mode='constant', constant_values=0)\n",
    "    \n",
    "    kernel_height, kernel_width = kernel.shape[:2]\n",
    "    padded_height, padded_width = image_padded.shape[:2]\n",
    "\n",
    "    # Determine the output dimensions\n",
    "    output_height = (padded_height - kernel_height) // stride + 1\n",
    "    output_width = (padded_width - kernel_width) // stride + 1\n",
    "\n",
    "    # Create an empty image to store the output\n",
    "    new_image = np.zeros((output_height, output_width, image.shape[-1]))\n",
    "    \n",
    "    # Perform the convolution\n",
    "    for x in range(0, padded_height - kernel_height + 1, stride):\n",
    "        for y in range(0, padded_width - kernel_width + 1, stride):\n",
    "            new_image[x // stride, y // stride] = np.sum(\n",
    "                image_padded[x:x + kernel_height, y:y + kernel_width] * kernel, axis=(0, 1)\n",
    "            )\n",
    "    return new_image\n",
    "\n",
    "# Pooling function\n",
    "def pool2d(image, pool_size, stride, pooling_type='max'):\n",
    "    # Determine the output dimensions\n",
    "    output_height = (image.shape[0] - pool_size) // stride + 1\n",
    "    output_width = (image.shape[1] - pool_size) // stride + 1\n",
    "\n",
    "    # Create an empty image to store the output\n",
    "    new_image = np.zeros((output_height, output_width, image.shape[-1]))\n",
    "\n",
    "    # Perform the pooling\n",
    "    for x in range(0, image.shape[0] - pool_size + 1, stride):\n",
    "        for y in range(0, image.shape[1] - pool_size + 1, stride):\n",
    "            if pooling_type == 'max':\n",
    "                new_image[x // stride, y // stride] = np.max(\n",
    "                    image[x:x + pool_size, y:y + pool_size], axis=(0, 1)\n",
    "                )\n",
    "            elif pooling_type == 'average':\n",
    "                new_image[x // stride, y // stride] = np.mean(\n",
    "                    image[x:x + pool_size, y:y + pool_size], axis=(0, 1)\n",
    "                )\n",
    "    return new_image\n",
    "\n",
    "# ReLU Activation function\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Softmax function\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# MLP implementation\n",
    "def mlp(input_layer, weights, biases):\n",
    "    return softmax(np.dot(weights, input_layer) + biases)\n",
    "\n",
    "# Example input (random image data and random filter for convolution)\n",
    "input_image = np.random.rand(32, 32, 3)\n",
    "kernel = np.random.rand(3, 3, 3)\n",
    "stride = 1\n",
    "padding = 0\n",
    "\n",
    "# Convolution 3x3\n",
    "convoluted_image = convolve2d(input_image, kernel, stride, padding)\n",
    "\n",
    "# Pooling\n",
    "pooled_image = pool2d(convoluted_image, 2, 2, 'max')\n",
    "\n",
    "# Flatten the image\n",
    "flattened = pooled_image.flatten()\n",
    "\n",
    "# MLP (assuming some random weights and biases)\n",
    "weights = np.random.rand(10, flattened.size)  # 10 classes for example\n",
    "biases = np.random.rand(10)\n",
    "\n",
    "# Output from MLP\n",
    "output = mlp(flattened, weights, biases)\n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7601fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsalan/anaconda3/lib/python3.8/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetching the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "# Normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(mnist.data)\n",
    "y = mnist.target.astype(np.uint8)\n",
    "\n",
    "# Reshaping the data to have a channel dimension, here 1 channel because MNIST is grayscale\n",
    "X_reshaped = X.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Defining the convolution operation\n",
    "def convolve2d_manual(input_data, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Perform a 2D convolution operation manually without using built-in convolve functions.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_data: Input data or image (2D array)\n",
    "    - kernel: Convolution kernel (2D array)\n",
    "    - stride: Stride of the convolution operation\n",
    "    - padding: Zero-padding added to the input\n",
    "    \n",
    "    Returns:\n",
    "    - output: The result of the convolution operation\n",
    "    \"\"\"\n",
    "    # Adding zero padding to the input data\n",
    "    if padding > 0:\n",
    "        input_data = np.pad(input_data, [(padding, padding), (padding, padding)], mode='constant', constant_values=0)\n",
    "    \n",
    "    # Calculating the dimensions of the output\n",
    "    output_height = ((input_data.shape[0] - kernel.shape[0]) // stride) + 1\n",
    "    output_width = ((input_data.shape[1] - kernel.shape[1]) // stride) + 1\n",
    "    output = np.zeros((output_height, output_width))\n",
    "    \n",
    "    # Performing the convolution operation\n",
    "    for y in range(0, output_height):\n",
    "        for x in range(0, output_width):\n",
    "            output[y, x] = np.sum(input_data[y*stride:y*stride+kernel.shape[0], x*stride:x*stride+kernel.shape[1]] * kernel)\n",
    "    return output\n",
    "\n",
    "# Defining pooling operation\n",
    "def pooling_manual(input_data, size=2, stride=2, mode='max'):\n",
    "    \"\"\"\n",
    "    Perform a pooling operation manually without using built-in pool functions.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_data: Input data or feature map (2D array)\n",
    "    - size: The size of the window to take a max or average over\n",
    "    - stride: The stride of the pooling operation\n",
    "    - mode: The pooling mode - 'max' for max pooling or 'avg' for average pooling\n",
    "    \n",
    "    Returns:\n",
    "    - output: The result of the pooling operation\n",
    "    \"\"\"\n",
    "    # Calculating the dimensions of the output\n",
    "    output_height = ((input_data.shape[0] - size) // stride) + 1\n",
    "    output_width = ((input_data.shape[1] - size) // stride) + 1\n",
    "    output = np.zeros((output_height, output_width))\n",
    "    \n",
    "    # Performing the pooling operation\n",
    "    for y in range(0, output_height):\n",
    "        for x in range(0, output_width):\n",
    "            window = input_data[y*stride:y*stride+size, x*stride:x*stride+size]\n",
    "            if mode == 'max':\n",
    "                output[y, x] = np.max(window)\n",
    "            elif mode == 'avg':\n",
    "                output[y, x] = np.mean(window)\n",
    "    return output\n",
    "\n",
    "# Creating a simple 3x3 convolution kernel for demonstration\n",
    "kernel = np.array([[1, 0, -1],\n",
    "                   [1, 0, -1],\n",
    "                   [1, 0, -1]])\n",
    "\n",
    "# Convolving the first image in the dataset\n",
    "convolved_image = convolve2d_manual(X_reshaped[0, :, :, 0], kernel)\n",
    "\n",
    "# Pooling the convolved image\n",
    "pooled_image = pooling_manual(convolved_image, mode='max')\n",
    "\n",
    "# Displaying the original, convolved, and pooled images\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 5))\n",
    "ax[0].imshow(X_reshaped[0, :, :, 0], cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(convolved_image, cmap='gray')\n",
    "ax[1].set_title('Convolved Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(pooled_image, cmap='gray')\n",
    "ax[2].set_title('Pooled Image')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a Multi\n",
    "# Fetching the MNIST dataset again\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "# Normalizing the data again\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(mnist.data)\n",
    "y = mnist.target.astype(np.uint8)\n",
    "\n",
    "# Splitting the dataset into training and test sets again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining the MLP classifier again\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64,), max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "# Training the MLP classifier on the training set\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the classifier on the test set\n",
    "test_score = mlp.score(X_test, y_test)\n",
    "\n",
    "# Print the test score\n",
    "print(f\"The test score of the MLP classifier is: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56cc339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09771437, 0.09976008, 0.09895422, 0.10102684, 0.10103402,\n",
       "        0.10196753, 0.09813206, 0.1000662 , 0.10096947, 0.10037521],\n",
       "       [0.09915239, 0.10057207, 0.10038062, 0.10033083, 0.1011093 ,\n",
       "        0.10141746, 0.09710186, 0.0987585 , 0.10122078, 0.0999562 ],\n",
       "       [0.09928585, 0.09839743, 0.10086476, 0.1014137 , 0.1012655 ,\n",
       "        0.10100233, 0.09746659, 0.09891252, 0.10050226, 0.10088906],\n",
       "       [0.09964296, 0.09998277, 0.09989744, 0.10047433, 0.10058792,\n",
       "        0.10179031, 0.09823333, 0.09869494, 0.10066029, 0.10003572],\n",
       "       [0.0986354 , 0.09988082, 0.10045291, 0.10099037, 0.10155249,\n",
       "        0.10093839, 0.09781693, 0.09908382, 0.1006316 , 0.10001726]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming the image preprocessing involves normalization and maybe some distortion, \n",
    "# we will just simulate this with a function that 'processes' images by a simple normalization for now.\n",
    "def preprocess_images(images):\n",
    "    # Normalize image data to 0-1\n",
    "    images_normalized = images / 255.0\n",
    "    return images_normalized\n",
    "\n",
    "# A simple DNN structure for simulation purposes\n",
    "class SimpleDNN:\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        # Simulate a simple neural network with random weights\n",
    "        self.weights = np.random.rand(input_shape, num_classes)\n",
    "    \n",
    "    def predict(self, image):\n",
    "        # Perform a simple matrix multiplication and softmax to simulate prediction\n",
    "        logits = np.dot(image, self.weights)\n",
    "        return np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "\n",
    "# Function to create and train a Multi-Column DNN\n",
    "def train_mcdnn(num_columns, input_shape, num_classes, images, labels):\n",
    "    # Create a list of DNNs\n",
    "    dnns = [SimpleDNN(input_shape, num_classes) for _ in range(num_columns)]\n",
    "    \n",
    "    # Simulate training and averaging predictions\n",
    "    predictions = np.zeros((len(images), num_classes))\n",
    "    for dnn in dnns:\n",
    "        # There is no actual training going on; we simulate this by just predicting with untrained networks\n",
    "        preds = dnn.predict(images)\n",
    "        predictions += preds\n",
    "        \n",
    "    # Average the predictions from each column\n",
    "    predictions /= num_columns\n",
    "    return predictions\n",
    "\n",
    "# Example usage\n",
    "num_classes = 10  # Just as an example, say we have 10 classes\n",
    "num_columns = 3   # Number of columns in the MCDNN\n",
    "input_shape = 784 # Example input shape (28x28 images flattened)\n",
    "\n",
    "# Simulate some data (e.g., MNIST)\n",
    "np.random.seed(0) # For reproducibility\n",
    "images = np.random.rand(100, input_shape) # 100 random images\n",
    "labels = np.random.randint(0, num_classes, 100) # 100 random labels\n",
    "\n",
    "# Preprocess the images\n",
    "processed_images = preprocess_images(images)\n",
    "\n",
    "# Train the MCDNN\n",
    "predictions = train_mcdnn(num_columns, input_shape, num_classes, processed_images, labels)\n",
    "\n",
    "# The predictions are now in `predictions` and we would typically calculate accuracy or other metrics here\n",
    "# However, since we have simulated data and a non-trained model, the accuracy would not be meaningful\n",
    "predictions[:5]  # Show the first 5 predictions for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3e46dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:37<00:00, 267686.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 42758804.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:13<00:00, 124436.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1217208.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 4608]' is invalid for input of size 346112",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a323ce569395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Clear gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a323ce569395>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mcolumn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0maveraged_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a323ce569395>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mcolumn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0maveraged_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a323ce569395>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# ... More layers if needed ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 4608]' is invalid for input of size 346112"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load and preprocess MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "class CNNColumn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNColumn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)  # Adding padding to maintain the size\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)  # Define conv2 with appropriate in/out channels\n",
    "        # Adjust the linear layer to match the output of the conv/pool layers\n",
    "        self.fc = nn.Linear(7 * 7 * 64, 10)  # Assuming the output is 7x7 after pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Adjust the view to match the fc layer input\n",
    "        x = x.view(-1, 7 * 7 * 64)  # Match the dimension with the fc layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class MCDNN(nn.Module):\n",
    "    def __init__(self, num_columns):\n",
    "        super(MCDNN, self).__init__()\n",
    "        self.columns = nn.ModuleList([CNNColumn() for _ in range(num_columns)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        column_outputs = [column(x) for column in self.columns]\n",
    "        averaged_output = torch.mean(torch.stack(column_outputs), dim=0)\n",
    "        return averaged_output\n",
    "\n",
    "# Instantiation, Training, Evaluation (Example Structure)\n",
    "num_columns = 5\n",
    "model = MCDNN(num_columns)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training and Evaluation\n",
    "num_epochs = 10  # Adjust as needed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if possible\n",
    "\n",
    "model.to(device)  # Move the model to the device\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            test_loss += loss_fn(outputs, labels).item()\n",
    "            test_acc += (outputs.argmax(dim=1) == labels).float().sum().item()\n",
    "\n",
    "    test_loss /= len(testloader)\n",
    "    test_acc /= len(testloader.dataset)\n",
    "    print(f\"Epoch {epoch+1}, Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd183d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the CNN architecture (similar to AlexNet)\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):  # CIFAR-10 has 10 classes\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# CIFAR-10 loading and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Resize images to size used by AlexNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Initialize the network\n",
    "net = AlexNet(num_classes=10)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save the trained model\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c2432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define a simple neural network with dropout\n",
    "class SimpleNetWithDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNetWithDropout, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(32 * 32 * 3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5)  # 50% probability of dropping out each neuron\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5)  # 50% probability of dropping out each neuron\n",
    "        )\n",
    "        self.layer3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the image\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Transform and load the CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize the network\n",
    "net = SimpleNetWithDropout()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradient buffers\n",
    "\n",
    "        outputs = net(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:  # Print every 200 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 200}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save the trained model\n",
    "PATH = './cifar_net_with_dropout.pth'\n",
    "torch.save(net.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1cbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the NetworkInNetwork model\n",
    "class NIN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(NIN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 192, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(192, 160, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(160, 96, kernel_size=1)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(96 * 7 * 7, 384)\n",
    "        self.fc2 = nn.Linear(384, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "# Create train and test dataloaders\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NIN().to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test accuracy\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Accuracy: {100*correct/total:.2f}%')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'nin_mnist.pth')\n",
    "\n",
    "print('Model saved successfully!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cbc518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the MLP convolutional block\n",
    "class MlpConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MlpConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# Define the Network In Network model\n",
    "class NIN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(NIN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            MlpConv(192, 160),\n",
    "            MlpConv(160, 96),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "            nn.Conv2d(96, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            MlpConv(192, 192),\n",
    "            MlpConv(192, 192),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "            nn.Conv2d(192, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            MlpConv(192, 192),\n",
    "            MlpConv(192, num_classes),\n",
    "        )\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        x = x.view(x.size(0), -1) # Flatten the tensor\n",
    "        return x\n",
    "\n",
    "# Load and normalize the CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Instantiate the NIN model\n",
    "net = NIN(num_classes=10)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(30):  # Loop over the dataset\n",
    "        running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Testing the model\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(net.state_dict(), 'nin_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14dde5f",
   "metadata": {},
   "source": [
    "# Very Deep Convolutional Networks for Large-Scale Image Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb28016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, MaxPooling2D, BatchNormalization, ReLU, Softmax\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load dataset\n",
    "(input_train, target_train), (input_test, target_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train.astype('float32') / 255.0\n",
    "input_test = input_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "target_train = to_categorical(target_train, 10)\n",
    "target_test = to_categorical(target_test, 10)\n",
    "\n",
    "# Define the model\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # First Conv Block\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Second Conv Block\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Third Conv Block\n",
    "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Fourth Conv Block\n",
    "    x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Fifth Conv Block\n",
    "    x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_model((32, 32, 3), 10)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16981a6b",
   "metadata": {},
   "source": [
    "# Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df14803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "\n",
    "# Load and preprocess CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Define custom BatchNormalization layer (assuming image reflects element-wise BN)\n",
    "class EltwiseBatchNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(EltwiseBatchNormalization, self).__init__(**kwargs)\n",
    "        self.gamma = tf.Variable(tf.ones_initializer()(shape=(32,)))\n",
    "        self.beta = tf.Variable(tf.zeros_initializer()(shape=(32,)))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mean, var = tf.nn.moments(inputs, -1, keepdims=True)\n",
    "        std = tf.math.sqrt(var + 1e-7)\n",
    "        normalized = (inputs - mean) / std * self.gamma + self.beta\n",
    "        return normalized\n",
    "\n",
    "# Create deep neural network architecture\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = EltwiseBatchNormalization()(x)  # Use custom BN layer\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = EltwiseBatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = EltwiseBatchNormalization()(x)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = EltwiseBatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create and train the model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_test, y_test))\n",
    "model.save('batchnorm_dnn.h5')\n",
    "\n",
    "print('Model trained and saved successfully!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c44716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define a neural network with batch normalization\n",
    "class BatchNormNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BatchNormNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.bn3 = nn.BatchNorm1d(120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.bn4 = nn.BatchNorm1d(84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.bn3(self.fc1(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.bn4(self.fc2(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "# Transform and load the CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Instantiate the network\n",
    "net = BatchNormNet()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Testing loop\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91b4ab",
   "metadata": {},
   "source": [
    "# Delving Deep into Recti ers: Surpassing Human-Level Performance on ImageNet Classication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3755a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define a custom Parametric ReLU activation\n",
    "class ParametricReLU(nn.Module):\n",
    "    def __init__(self, num_parameters):\n",
    "        super(ParametricReLU, self).__init__()\n",
    "        self.num_parameters = num_parameters\n",
    "        self.alpha = nn.Parameter(torch.zeros(num_parameters))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(x) - self.alpha * F.relu(-x)\n",
    "\n",
    "# Define a neural network with parametric ReLUs\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.prelu1 = ParametricReLU(6)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.prelu2 = ParametricReLU(16)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.prelu3 = ParametricReLU(120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.prelu4 = ParametricReLU(84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prelu1(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.prelu2(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.prelu3(self.fc1(x))\n",
    "        x = self.prelu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # All dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "# Initialize weights function based on the paper's specifications\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# CIFAR-10 dataset transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load and normalize CIFAR-10 training set\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Load and normalize CIFAR-10 test set\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Network, loss function, and optimizer\n",
    "net = Net()\n",
    "net.apply(weights_init)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[Epoch: {epoch + 1}, Batch: {i + 1}] loss: {running_loss / 2000}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Test the network on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ce4a83",
   "metadata": {},
   "source": [
    "# Rethinking the Inception Architecture for Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def create_inceptionv3_model(num_classes):\n",
    "  # Load the InceptionV3 model without the top layer.\n",
    "  base_model = InceptionV3(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "  # Add a global average pooling layer.\n",
    "  x = base_model.output\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "  # Add a dropout layer.\n",
    "  x = Dropout(0.5)(x)\n",
    "\n",
    "  # Add a dense layer with the specified number of classes.\n",
    "  x = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "  # Create the final model.\n",
    "  model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "  # Freeze the base layers of the model.\n",
    "  for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "  return model\n",
    "\n",
    "# Compile the model.\n",
    "model = create_inceptionv3_model(1000)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Print a summary of the model.\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f2c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Concatenate, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "# Define the inception module\n",
    "def inception_module(x,\n",
    "                     filters_1x1,\n",
    "                     filters_3x3_reduce,\n",
    "                     filters_3x3,\n",
    "                     filters_5x5_reduce,\n",
    "                     filters_5x5,\n",
    "                     filters_pool_proj):\n",
    "    path1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "    path2 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    path2 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu')(path2)\n",
    "\n",
    "    path3 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    path3 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu')(path3)\n",
    "\n",
    "    path4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    path4 = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu')(path4)\n",
    "\n",
    "    return Concatenate(axis=-1)([path1, path2, path3, path4])\n",
    "\n",
    "# Build the model\n",
    "input_layer = Input(shape=(299, 299, 3))\n",
    "\n",
    "x = Conv2D(32, (3, 3), strides=(2, 2), padding='valid', activation='relu')(input_layer)\n",
    "x = Conv2D(32, (3, 3), padding='valid', activation='relu')(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(80, (1, 1), padding='valid', activation='relu')(x)\n",
    "x = Conv2D(192, (3, 3), padding='valid', activation='relu')(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "# Inception modules\n",
    "x = inception_module(x, 64, 96, 128, 16, 32, 32)\n",
    "x = inception_module(x, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = inception_module(x, 192, 96, 208, 16, 48, 64)\n",
    "x = inception_module(x, 160, 112, 224, 24, 64, 64)\n",
    "x = inception_module(x, 128, 128, 256, 24, 64, 64)\n",
    "x = inception_module(x, 112, 144, 288, 32, 64, 64)\n",
    "x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
    "x = inception_module(x, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "# Global Average Pooling\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Dense layer\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "\n",
    "# Classifier\n",
    "output = Dense(1000, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = preprocess_input(x_train)\n",
    "x_test = preprocess_input(x_test)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Resize images to match the input size of the model\n",
    "x_train = tf.image.resize(x_train, (299, 299))\n",
    "x_test = tf.image.resize(x_test, (299, 299))\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(x_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf88321",
   "metadata": {},
   "source": [
    "# Deep Residual Learning for Image Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f87ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * 4)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, 64)\n",
    "        self.layer2 = self._make_layer(block, 128, 128, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, 256, stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, 512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * 4:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * 4, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * 4))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(block(out_channels * 4, out_channels))\n",
    "        self.in_channels = out_channels * 4\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = ResNet(BottleneckBlock)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a41d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != self.expansion*out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion*out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# Define the ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "def ResNet18():\n",
    "    return ResNet(ResidualBlock, [2, 2, 2, 2])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Initialize the model and loss function\n",
    "model = ResNet18()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b64b101",
   "metadata": {},
   "source": [
    "# Identity Mappings in Deep Residual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, 2)  # Change number of blocks to 2 as per the image\n",
    "        self.layer2 = self._make_layer(block, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, 2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * 4:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * 4, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * 4))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(block(out_channels * 4, out_channels))\n",
    "        self.in_channels = out_channels * 4\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = ResNet(ResidualBlock)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    trainset = datasets.CIFAR10(root=\"~/torch_data\", train=True, download=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b2dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the identity block\n",
    "def identity_block(X, f, filters):\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component\n",
    "    X = Conv2D(filters=F1, kernel_size=1, strides=(1,1), padding='valid')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component\n",
    "    X = Conv2D(filters=F2, kernel_size=f, strides=(1,1), padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component\n",
    "    X = Conv2D(filters=F3, kernel_size=1, strides=(1,1), padding='valid')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Define the convolutional block\n",
    "def convolutional_block(X, f, filters, s=2):\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component\n",
    "    X = Conv2D(F1, (1, 1), strides=(s,s))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component\n",
    "    X = Conv2D(F2, (f, f), strides=(1,1), padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component\n",
    "    X = Conv2D(F3, (1, 1), strides=(1,1), padding='valid')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "\n",
    "    # Shortcut Path\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides=(s,s), padding='valid')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3)(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Define the ResNet model\n",
    "def ResNet50(input_shape=(32, 32, 3), classes=10):\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2))(X_input)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    X = GlobalAveragePooling2D()(X)\n",
    "    # Output layer\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize image vectors\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Instantiate the model\n",
    "model = ResNet50(input_shape=(32, 32, 3), classes=10)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "preds = model.evaluate(x_test, y_test)\n",
    "print('Loss = ' + str(preds[0]))\n",
    "print('Test Accuracy = ' + str(preds[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c026a3",
   "metadata": {},
   "source": [
    "# Deep Networks with Stochastic Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa77225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class StochasticDepth(layers.Wrapper):\n",
    "    def __init__(self, layer, p, **kwargs):\n",
    "        super(StochasticDepth, self).__init__(layer, **kwargs)\n",
    "        self.p = p\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            bernoulli = tf.random.uniform(tf.shape(inputs), 0, 1)\n",
    "            mask = tf.cast(bernoulli >= self.p, tf.float32)\n",
    "            return self.layer(inputs * mask)\n",
    "        else:\n",
    "            return self.layer(inputs)\n",
    "\n",
    "\n",
    "def create_resnet_block(filters, stride=1, p=0.5):\n",
    "    conv1 = layers.Conv2D(filters, kernel_size=3, strides=stride, padding=\"same\")\n",
    "    bn1 = layers.BatchNormalization()\n",
    "    relu1 = layers.ReLU()\n",
    "    conv2 = layers.Conv2D(filters, kernel_size=3, strides=1, padding=\"same\")\n",
    "    bn2 = layers.BatchNormalization()\n",
    "    shortcut = layers.Conv2D(filters, kernel_size=1, strides=stride, padding=\"same\")\n",
    "    bn3 = layers.BatchNormalization()\n",
    "\n",
    "    residual = StochasticDepth(relu1(bn1(conv1(inputs))))(inputs)\n",
    "    residual = layers.add([residual, StochasticDepth(conv2(bn2(relu1(residual))))(residual)])\n",
    "    output = StochasticDepth(layers.add([shortcut(bn3(inputs)), residual]))(inputs)\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_resnet_model(num_classes, p=0.5):\n",
    "    inputs = layers.Input(shape=(32, 32, 3))\n",
    "    conv1 = layers.Conv2D(64, kernel_size=7, strides=2, padding=\"same\")\n",
    "    bn1 = layers.BatchNormalization()\n",
    "    relu1 = layers.ReLU()\n",
    "    maxpool1 = layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding=\"same\")\n",
    "\n",
    "    block1 = create_resnet_block(64)\n",
    "    block2 = create_resnet_block(64, stride=2)\n",
    "    block3 = create_resnet_block(128, stride=2)\n",
    "    block4 = create_resnet_block(256, stride=2)\n",
    "\n",
    "    avgpool = layers.AvgPool2D()\n",
    "    fc = layers.Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    outputs = fc(avgpool(block4(block3(block2(block1(relu1(bn1(conv1(inputs))))))))))\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_resnet_model(100, p=0.2)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Define the Stochastic Depth Block\n",
    "class StochasticDepthBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, p):\n",
    "        super(StochasticDepthBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "        self.p = p\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            if torch.rand(1).item() < self.p:\n",
    "                return self.shortcut(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# Define the ResNet with Stochastic Depth\n",
    "class ResNetStochastic(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNetStochastic, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1, p=1.0)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2, p=0.8)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2, p=0.6)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride, p):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride, p))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Model architecture\n",
    "def ResNet110():\n",
    "    return ResNetStochastic(StochasticDepthBlock, [18, 18, 18])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize the model\n",
    "model = ResNet110().cuda()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD()\n",
    "model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Learning rate adjustment\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = 0.1\n",
    "    if epoch >= 81:\n",
    "        lr /= 10\n",
    "    if epoch >= 122:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "# Training the model\n",
    "def train(epoch):\n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    model.train()\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        print(f'Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f}% ({correct}/{total})')\n",
    "\n",
    "# Testing the model\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            print(f'Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f}% ({correct}/{total})')\n",
    "\n",
    "for epoch in range(0, 164):\n",
    "    train(epoch)\n",
    "    test(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397cd7f",
   "metadata": {},
   "source": [
    "# Wide Residual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class WideResBlock(layers.Layer):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, k=1, **kwargs):\n",
    "        super(WideResBlock, self).__init__(**kwargs)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.k = k\n",
    "\n",
    "        self.conv1 = layers.Conv2D(in_channels * k, kernel_size=3, strides=stride, padding=\"same\")\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.ReLU()\n",
    "\n",
    "        self.conv2 = layers.Conv2D(out_channels, kernel_size=3, strides=1, padding=\"same\")\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = layers.Conv2D(out_channels, kernel_size=1, strides=stride, padding=\"same\")\n",
    "            self.bn3 = layers.BatchNormalization()\n",
    "        else:\n",
    "            self.shortcut = layers.Lambda(lambda x: x)\n",
    "            self.bn3 = None\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        out = self.conv1(inputs)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        shortcut = self.shortcut(inputs)\n",
    "        if self.bn3 is not None:\n",
    "            shortcut = self.bn3(shortcut)\n",
    "\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "def create_wrn_model(num_classes, depth=40, k=10, width=4):\n",
    "    inputs = layers.Input(shape=(32, 32, 3))\n",
    "    conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding=\"same\")\n",
    "    bn1 = layers.BatchNormalization()\n",
    "    relu1 = layers.ReLU()\n",
    "\n",
    "    # First Residual Block with 16 output channels\n",
    "    out = WideResBlock(16, 16, k=k)(relu1(bn1(conv1(inputs))))\n",
    "\n",
    "    # Residual Blocks based on the image\n",
    "    for i in range(depth):\n",
    "        out = WideResBlock(16 * width**i, 16 * width**(i+1), stride=2 if (i // 6) % 2 == 1 else 1, k=k)(out)\n",
    "\n",
    "    avgpool = layers.AvgPool2D()\n",
    "    fc = layers.Dense(num_classes, activation=\"softmax\")(avgpool(out))\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=fc)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_wrn_model(100, depth=40, k=10, width=4)  # As per the image\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Define the Wide Residual Block\n",
    "class WideResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, dropRate=0.0):\n",
    "        super(WideResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout = nn.Dropout(p=dropRate)\n",
    "        self.equalInOut = (in_channels == out_channels)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False) or None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut:\n",
    "            x = self.relu(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu(self.bn1(x))\n",
    "        out = self.relu(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.dropout is not None:\n",
    "            out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "# Define the Wide ResNet\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth, widen_factor, dropRate, num_classes):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert ((depth-4) % 6 == 0), 'Wide-resnet depth should be 6n+4'\n",
    "        n = (depth-4) // 6\n",
    "        block = WideResidualBlock\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = self._wide_layer(block, nChannels[0], nChannels[1], n, stride=1, dropRate=dropRate)\n",
    "        # 2nd block\n",
    "        self.block2 = self._wide_layer(block, nChannels[1], nChannels[2], n, stride=2, dropRate=dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = self._wide_layer(block, nChannels[2], nChannels[3], n, stride=2, dropRate=dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "    def _wide_layer(self, block, in_channels, out_channels, num_blocks, stride, dropRate):\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            stride = stride if i == 0 else 1\n",
    "            layers.append(block(in_channels, out_channels, stride, dropRate))\n",
    "            in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = torch.nn.functional.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        return self.fc(out)\n",
    "\n",
    "# Example instantiation for WRN-28-10 with dropout\n",
    "model = WideResNet(depth=28, widen_factor=10, dropRate=0.3, num_classes=10)\n",
    "\n",
    "# Data loading\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce7791e",
   "metadata": {},
   "source": [
    "# Aggregated Residual Transformations for Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, cardinality, strides=1, dilation=1):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        group_width = out_channels // cardinality\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(group_width)\n",
    "        self.conv2 = nn.Conv2d(group_width, group_width, kernel_size=3, padding=dilation, stride=strides, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(group_width)\n",
    "        self.conv3 = nn.Conv2d(group_width, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels or strides != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, stride=strides, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self, block, cardinality, base_width, num_classes=1000):\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.cardinality = cardinality\n",
    "        self.base_width = base_width\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.base_width, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.base_width)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, self.base_width, self.base_width, cardinality, 3)\n",
    "        self.layer2 = self._make_layer(block, self.base_width * 2, self.base_width * 2, cardinality, 4, stride=2)\n",
    "        self.layer3 = self._make_layer(block, self.base_width * 4, self.base_width * 4, cardinality, 6, stride=2)\n",
    "        self.layer4 = self._make_layer(block, self.base_width * 8, self.base_width * 8, cardinality, 3, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(self.base_width * 8, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, in_planes, cardinality, num_blocks, stride=1):\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            if i == 0:\n",
    "                layers.append(block(in_planes, planes, cardinality, stride))\n",
    "            else:\n",
    "                layers.append(block(planes, planes, cardinality))\n",
    "            in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ba2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the Aggregated Residual Transformation Block\n",
    "class AggregatedResidualTransformation(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, groups, reduction):\n",
    "        super(AggregatedResidualTransformation, self).__init__()\n",
    "        self.reduced_channels = out_channels // reduction\n",
    "        self.conv1 = nn.Conv2d(in_channels, self.reduced_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.reduced_channels)\n",
    "        self.conv2 = nn.Conv2d(self.reduced_channels, self.reduced_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.reduced_channels)\n",
    "        self.conv3 = nn.Conv2d(self.reduced_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# Define the ResNeXt Model\n",
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self, block, num_blocks, cardinality, bottleneck_width, num_classes=10):\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.cardinality = cardinality\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 256, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 512, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 1024, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 2048, num_blocks[3], stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            layers.append(block(self.in_channels, out_channels, stride if i == 0 else 1, self.cardinality, self.bottleneck_width))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Define ResNeXt model parameters\n",
    "def ResNeXt50_2x32d():\n",
    "    return ResNeXt(AggregatedResidualTransformation, [3, 4, 6, 3], cardinality=32, bottleneck_width=2)\n",
    "\n",
    "# Prepare the CIFAR10 dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870e7e6",
   "metadata": {},
   "source": [
    "# Densely Connected Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b351549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_convs):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_convs):\n",
    "            layers.append(nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(growth_rate))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            in_channels += growth_rate\n",
    "        self.denseblock = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([x, self.denseblock(x)], 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransitionDown(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TransitionDown, self).__init__()\n",
    "        self.add_module('conv', nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growth_rate, block_config, num_classes=1000):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.growth_rate = growth_rate\n",
    "\n",
    "        num_convs = [3, 3, 3, 3]  # As per the image\n",
    "        num_filters = 2 * growth_rate  # As per the image\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, num_filters, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_filters)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.denseblocks = nn.ModuleList()\n",
    "        for i in range(len(num_convs)):\n",
    "            num_in_filters = num_filters if i == 0 else num_filters + growth_rate * i\n",
    "            num_out_filters = num_filters + growth_rate * (sum(num_convs[:i + 1]) - 1)\n",
    "            self.denseblocks.append(DenseBlock(num_in_filters, growth_rate, num_convs[i]))\n",
    "            if i != len(num_convs) - 1:\n",
    "                self.denseblocks.append(TransitionDown(num_out_filters, num_out_filters // 2))\n",
    "                num_filters = num_out_filters // 2\n",
    "\n",
    "        self.fc = nn.Linear(num_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool1(out)\n",
    "\n",
    "        for denseblock, transition in zip(self.denseblocks[:-2], self.denseblocks[2::2]):\n",
    "            out = denseblock(out)\n",
    "            out = transition(out)\n",
    "\n",
    "        out = self.denseblocks[-1](out)\n",
    "        out = F.avg_pool2d(out, kernel_size=4)\n",
    "        out = torch. flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "model = DenseNet(growth_rate=12, block_config=[4, 4, 4, 3], num_classes=1000)  # As per the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root=\"~/torch_data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496c6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the Dense Layer\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, 4 * growth_rate, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(4 * growth_rate)\n",
    "        self.conv2 = nn.Conv2d(4 * growth_rate, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat([x, out], 1)\n",
    "        return out\n",
    "\n",
    "# Define the Dense Block\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, growth_rate):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(DenseLayer(in_channels + i * growth_rate, growth_rate))\n",
    "        self.layer = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "# Define the Transition Layer\n",
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(F.relu(self.bn(x)))\n",
    "        out = self.pool(out)\n",
    "        return out\n",
    "\n",
    "# Define the DenseNet\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growth_rate, block_config, num_classes=10):\n",
    "        super(DenseNet, self).__init__()\n",
    "        num_blocks = len(block_config)\n",
    "        num_channels = 2 * growth_rate\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, num_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        blocks = []\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            blocks.append(DenseBlock(num_layers=num_layers, in_channels=num_channels, growth_rate=growth_rate))\n",
    "            num_channels += num_layers * growth_rate\n",
    "            if i != num_blocks - 1:\n",
    "                blocks.append(TransitionLayer(in_channels=num_channels, out_channels=num_channels // 2))\n",
    "                num_channels = num_channels // 2\n",
    "        \n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.bn = nn.BatchNorm2d(num_channels)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(num_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.blocks(out)\n",
    "        out = self.bn(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Model architecture\n",
    "def DenseNet121():\n",
    "    return DenseNet(growth_rate=32, block_config=[6, 12, 24, 16])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = DenseNet121().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/10], Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# Testing the\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy of the model on the 10000 test images: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e38433",
   "metadata": {},
   "source": [
    "# Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef04b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.applications.InceptionResNetV2(weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.inception_v3(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class InceptionA(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionA, self).__init__()\n",
    "        self.branch1x1 = nn.Conv2d(in_channels, 64, kernel_size=1, bias=False)\n",
    "        self.bn1x1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.branch3x3_reduce = nn.Conv2d(in_channels, 96, kernel_size=1, bias=False)\n",
    "        self.bn3x3_reduce = nn.BatchNorm2d(96)\n",
    "        self.branch3x3 = nn.Conv2d(96, 128, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn3x3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.branch1x3_reduce = nn.Conv2d(in_channels, 16, kernel_size=1, bias=False)\n",
    "        self.bn1x3_reduce = nn.BatchNorm2d(16)\n",
    "        self.branch1x3 = nn.Conv2d(16, 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1x3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.branch2x2_reduce = nn.Conv2d(in_channels, 32, kernel_size=1, bias=False)\n",
    "        self.bn2x2_reduce = nn.BatchNorm2d(32)\n",
    "        self.branch2x2 = nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2x2 = nn.BatchNorm2d(32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.bn1x1(self.branch1x1(x))\n",
    "\n",
    "        branch3x3 = self.bn3x3(self.branch3x3(self.bn3x3_reduce(self.branch3x3_reduce(x))))\n",
    "\n",
    "        branch1x3 = self.bn1x3(self.branch1x3(self.bn1x3_reduce(self.branch1x3_reduce(x))))\n",
    "\n",
    "        branch2x2 = self.bn2x2(self.branch2x2(self.bn2x2_reduce(self.branch2x2_reduce(x))))\n",
    "\n",
    "        outputs = [branch1x1, branch3x3, branch1x3, branch2x2]\n",
    "        return F.concat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionC(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionC, self).__init__()\n",
    "        self.branch1x1 = nn.Conv2d(in_channels, 192, kernel_size=1, bias=False)\n",
    "        self.bn1x1 = nn.BatchNorm2d(192)\n",
    "\n",
    "        self.branch3x3_reduce = nn.Conv2d(in_channels, 256, kernel_size=1, bias=False)\n",
    "        self.bn3x3_reduce = nn.BatchNorm2d(256)\n",
    "        self.branch3x3_0 = nn.Conv2d(256, 384, kernel_size=1, bias=False)\n",
    "        self.bn3x3_0 = nn.BatchNorm2d(384)\n",
    "        self.branch3x3_1 = nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn3x3_1 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.branch1x3_reduce = nn.Conv2d(in_channels, 384, kernel_size=1, bias=False)\n",
    "        self.bn1x3_reduce = nn.BatchNorm2d(384)\n",
    "        self.branch1x3_0 = nn.Conv2d(384, 256, kernel_size=1, bias=False)\n",
    "        self.branch1x3_1 = nn.Conv2d(384, 256, kernel_size=3, padding=1, bias=False) \n",
    "        self.bn1x3_1 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.branchpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.branch3x3_pool = nn.Conv2d(in_channels, 256, kernel_size=1, bias=False)\n",
    "        self.bn3x3_pool = nn.BatchNorm2d(256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Concatenate\n",
    "\n",
    "def inception_stem(input_tensor):\n",
    "    # Conv and Max Pooling layers as per Inception-v4 and Inception-ResNet-v1 & v2 stem structure\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='valid')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(80, (1, 1), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(192, (3, 3), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    # Assuming 'input_tensor' is of shape (299, 299, 3)\n",
    "    # You would typically return 'x' to feed into the rest of the network\n",
    "    return x\n",
    "\n",
    "# Define the model\n",
    "input_tensor = tf.keras.Input(shape=(299, 299, 3))\n",
    "output_tensor = inception_stem(input_tensor)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, AveragePooling2D, Concatenate\n",
    "\n",
    "def inception_a(input_tensor):\n",
    "    # Branch 1: 96 filters of 1x1 conv\n",
    "    branch1 = Conv2D(96, (1, 1), padding='same', activation='relu')(input_tensor)\n",
    "    \n",
    "    # Branch 2: 64 filters of 1x1 conv, followed by 96 filters of 3x3 conv\n",
    "    branch2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_tensor)\n",
    "    branch2 = Conv2D(96, (3, 3), padding='same', activation='relu')(branch2)\n",
    "    \n",
    "    # Branch 3: 64 filters of 1x1 conv, followed by 96 filters of 3x3 conv, followed by 96 filters of 3x3 conv\n",
    "    branch3 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_tensor)\n",
    "    branch3 = Conv2D(96, (3, 3), padding='same', activation='relu')(branch3)\n",
    "    branch3 = Conv2D(96, (3, 3), padding='same', activation='relu')(branch3)\n",
    "    \n",
    "    # Branch 4: 3x3 average pooling, followed by 96 filters of 1x1 conv\n",
    "    branch4 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input_tensor)\n",
    "    branch4 = Conv2D(96, (1, 1), padding='same', activation='relu')(branch4)\n",
    "    \n",
    "    # Concatenating the branches\n",
    "    x = Concatenate()([branch1, branch2, branch3, branch4])\n",
    "    return x\n",
    "\n",
    "# Example usage:\n",
    "input_tensor = tf.keras.Input(shape=(299, 299, 3))\n",
    "output_tensor = inception_a(input_tensor)\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, AveragePooling2D, concatenate\n",
    "\n",
    "def reduction_a(input_tensor, k=192, l=224, m=256, n=384):\n",
    "    # Implementation of Reduction-A block for Inception-v4 and Inception-ResNet-v1 & v2\n",
    "    # As per the diagram you've provided, the Reduction-A block is composed of several branches\n",
    "    # that are concatenated together\n",
    "\n",
    "    # Branch 1: 3x3 Max Pooling\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input_tensor)\n",
    "\n",
    "    # Branch 2: 3x3 Conv\n",
    "    branch3x3 = Conv2D(n, (3, 3), strides=(2, 2), padding='valid')(input_tensor)\n",
    "    branch3x3 = BatchNormalization()(branch3x3)\n",
    "    branch3x3 = Activation('relu')(branch3x3)\n",
    "\n",
    "    # Branch 3: 1x1 Conv -> 3x3 Conv -> 3x3 Conv\n",
    "    branch3x3dbl = Conv2D(k, (1, 1))(input_tensor)\n",
    "    branch3x3dbl = BatchNormalization()(branch3x3dbl)\n",
    "    branch3x3dbl = Activation('relu')(branch3x3dbl)\n",
    "\n",
    "    branch3x3dbl = Conv2D(l, (3, 3))(branch3x3dbl)\n",
    "    branch3x3dbl = BatchNormalization()(branch3x3dbl)\n",
    "    branch3x3dbl = Activation('relu')(branch3x3dbl)\n",
    "\n",
    "    branch3x3dbl = Conv2D(m, (3, 3), strides=(2, 2), padding='valid')(branch3x3dbl)\n",
    "    branch3x3dbl = BatchNormalization()(branch3x3dbl)\n",
    "    branch3x3dbl = Activation('relu')(branch3x3dbl)\n",
    "\n",
    "    # Concatenate all the branches\n",
    "    x = concatenate([branch_pool, branch3x3, branch3x3dbl], axis=3)\n",
    "\n",
    "    return x\n",
    "\n",
    "# Usage example\n",
    "input_tensor = tf.keras.Input(shape=(299, 299, 3))\n",
    "output_tensor = reduction_a(input_tensor)\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def inception_v4(input_shape):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # Build the stem block\n",
    "    x = stem(input_tensor)\n",
    "\n",
    "    # Build Inception-A blocks\n",
    "    # x = inception_a(x)\n",
    "\n",
    "    # Build Reduction-A block\n",
    "    # x = reduction_a(x)\n",
    "\n",
    "    # Build Inception-B blocks\n",
    "    # x = inception_b(x)\n",
    "\n",
    "    # Build Reduction-B block\n",
    "    # x = reduction_b(x)\n",
    "\n",
    "    # Build Inception-C blocks\n",
    "    # x = inception_c(x)\n",
    "\n",
    "    # Final pooling and prediction layers\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "    x = Dense(1000, activation='softmax')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(input_tensor, x, name='inception_v4')\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
