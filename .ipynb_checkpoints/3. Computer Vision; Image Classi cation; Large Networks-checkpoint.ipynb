{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575001da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.50590447e-24, 3.44861937e-27, 4.65997539e-24, 8.75116818e-26,\n",
       "       2.54694442e-35, 1.07614287e-37, 1.76913590e-15, 6.62121363e-20,\n",
       "       2.57847755e-10, 1.00000000e+00])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convolution function\n",
    "def convolve2d(image, kernel, stride, padding):\n",
    "    # Add zero padding to the input image\n",
    "    image_padded = np.pad(image, [(padding, padding), (padding, padding), (0, 0)], mode='constant', constant_values=0)\n",
    "    \n",
    "    kernel_height, kernel_width = kernel.shape[:2]\n",
    "    padded_height, padded_width = image_padded.shape[:2]\n",
    "\n",
    "    # Determine the output dimensions\n",
    "    output_height = (padded_height - kernel_height) // stride + 1\n",
    "    output_width = (padded_width - kernel_width) // stride + 1\n",
    "\n",
    "    # Create an empty image to store the output\n",
    "    new_image = np.zeros((output_height, output_width, image.shape[-1]))\n",
    "    \n",
    "    # Perform the convolution\n",
    "    for x in range(0, padded_height - kernel_height + 1, stride):\n",
    "        for y in range(0, padded_width - kernel_width + 1, stride):\n",
    "            new_image[x // stride, y // stride] = np.sum(\n",
    "                image_padded[x:x + kernel_height, y:y + kernel_width] * kernel, axis=(0, 1)\n",
    "            )\n",
    "    return new_image\n",
    "\n",
    "# Pooling function\n",
    "def pool2d(image, pool_size, stride, pooling_type='max'):\n",
    "    # Determine the output dimensions\n",
    "    output_height = (image.shape[0] - pool_size) // stride + 1\n",
    "    output_width = (image.shape[1] - pool_size) // stride + 1\n",
    "\n",
    "    # Create an empty image to store the output\n",
    "    new_image = np.zeros((output_height, output_width, image.shape[-1]))\n",
    "\n",
    "    # Perform the pooling\n",
    "    for x in range(0, image.shape[0] - pool_size + 1, stride):\n",
    "        for y in range(0, image.shape[1] - pool_size + 1, stride):\n",
    "            if pooling_type == 'max':\n",
    "                new_image[x // stride, y // stride] = np.max(\n",
    "                    image[x:x + pool_size, y:y + pool_size], axis=(0, 1)\n",
    "                )\n",
    "            elif pooling_type == 'average':\n",
    "                new_image[x // stride, y // stride] = np.mean(\n",
    "                    image[x:x + pool_size, y:y + pool_size], axis=(0, 1)\n",
    "                )\n",
    "    return new_image\n",
    "\n",
    "# ReLU Activation function\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Softmax function\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# MLP implementation\n",
    "def mlp(input_layer, weights, biases):\n",
    "    return softmax(np.dot(weights, input_layer) + biases)\n",
    "\n",
    "# Example input (random image data and random filter for convolution)\n",
    "input_image = np.random.rand(32, 32, 3)\n",
    "kernel = np.random.rand(3, 3, 3)\n",
    "stride = 1\n",
    "padding = 0\n",
    "\n",
    "# Convolution 3x3\n",
    "convoluted_image = convolve2d(input_image, kernel, stride, padding)\n",
    "\n",
    "# Pooling\n",
    "pooled_image = pool2d(convoluted_image, 2, 2, 'max')\n",
    "\n",
    "# Flatten the image\n",
    "flattened = pooled_image.flatten()\n",
    "\n",
    "# MLP (assuming some random weights and biases)\n",
    "weights = np.random.rand(10, flattened.size)  # 10 classes for example\n",
    "biases = np.random.rand(10)\n",
    "\n",
    "# Output from MLP\n",
    "output = mlp(flattened, weights, biases)\n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7601fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsalan/anaconda3/lib/python3.8/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetching the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "# Normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(mnist.data)\n",
    "y = mnist.target.astype(np.uint8)\n",
    "\n",
    "# Reshaping the data to have a channel dimension, here 1 channel because MNIST is grayscale\n",
    "X_reshaped = X.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Defining the convolution operation\n",
    "def convolve2d_manual(input_data, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Perform a 2D convolution operation manually without using built-in convolve functions.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_data: Input data or image (2D array)\n",
    "    - kernel: Convolution kernel (2D array)\n",
    "    - stride: Stride of the convolution operation\n",
    "    - padding: Zero-padding added to the input\n",
    "    \n",
    "    Returns:\n",
    "    - output: The result of the convolution operation\n",
    "    \"\"\"\n",
    "    # Adding zero padding to the input data\n",
    "    if padding > 0:\n",
    "        input_data = np.pad(input_data, [(padding, padding), (padding, padding)], mode='constant', constant_values=0)\n",
    "    \n",
    "    # Calculating the dimensions of the output\n",
    "    output_height = ((input_data.shape[0] - kernel.shape[0]) // stride) + 1\n",
    "    output_width = ((input_data.shape[1] - kernel.shape[1]) // stride) + 1\n",
    "    output = np.zeros((output_height, output_width))\n",
    "    \n",
    "    # Performing the convolution operation\n",
    "    for y in range(0, output_height):\n",
    "        for x in range(0, output_width):\n",
    "            output[y, x] = np.sum(input_data[y*stride:y*stride+kernel.shape[0], x*stride:x*stride+kernel.shape[1]] * kernel)\n",
    "    return output\n",
    "\n",
    "# Defining pooling operation\n",
    "def pooling_manual(input_data, size=2, stride=2, mode='max'):\n",
    "    \"\"\"\n",
    "    Perform a pooling operation manually without using built-in pool functions.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_data: Input data or feature map (2D array)\n",
    "    - size: The size of the window to take a max or average over\n",
    "    - stride: The stride of the pooling operation\n",
    "    - mode: The pooling mode - 'max' for max pooling or 'avg' for average pooling\n",
    "    \n",
    "    Returns:\n",
    "    - output: The result of the pooling operation\n",
    "    \"\"\"\n",
    "    # Calculating the dimensions of the output\n",
    "    output_height = ((input_data.shape[0] - size) // stride) + 1\n",
    "    output_width = ((input_data.shape[1] - size) // stride) + 1\n",
    "    output = np.zeros((output_height, output_width))\n",
    "    \n",
    "    # Performing the pooling operation\n",
    "    for y in range(0, output_height):\n",
    "        for x in range(0, output_width):\n",
    "            window = input_data[y*stride:y*stride+size, x*stride:x*stride+size]\n",
    "            if mode == 'max':\n",
    "                output[y, x] = np.max(window)\n",
    "            elif mode == 'avg':\n",
    "                output[y, x] = np.mean(window)\n",
    "    return output\n",
    "\n",
    "# Creating a simple 3x3 convolution kernel for demonstration\n",
    "kernel = np.array([[1, 0, -1],\n",
    "                   [1, 0, -1],\n",
    "                   [1, 0, -1]])\n",
    "\n",
    "# Convolving the first image in the dataset\n",
    "convolved_image = convolve2d_manual(X_reshaped[0, :, :, 0], kernel)\n",
    "\n",
    "# Pooling the convolved image\n",
    "pooled_image = pooling_manual(convolved_image, mode='max')\n",
    "\n",
    "# Displaying the original, convolved, and pooled images\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 5))\n",
    "ax[0].imshow(X_reshaped[0, :, :, 0], cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(convolved_image, cmap='gray')\n",
    "ax[1].set_title('Convolved Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(pooled_image, cmap='gray')\n",
    "ax[2].set_title('Pooled Image')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a Multi\n",
    "# Fetching the MNIST dataset again\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "# Normalizing the data again\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(mnist.data)\n",
    "y = mnist.target.astype(np.uint8)\n",
    "\n",
    "# Splitting the dataset into training and test sets again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining the MLP classifier again\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64,), max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "# Training the MLP classifier on the training set\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the classifier on the test set\n",
    "test_score = mlp.score(X_test, y_test)\n",
    "\n",
    "# Print the test score\n",
    "print(f\"The test score of the MLP classifier is: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56cc339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09771437, 0.09976008, 0.09895422, 0.10102684, 0.10103402,\n",
       "        0.10196753, 0.09813206, 0.1000662 , 0.10096947, 0.10037521],\n",
       "       [0.09915239, 0.10057207, 0.10038062, 0.10033083, 0.1011093 ,\n",
       "        0.10141746, 0.09710186, 0.0987585 , 0.10122078, 0.0999562 ],\n",
       "       [0.09928585, 0.09839743, 0.10086476, 0.1014137 , 0.1012655 ,\n",
       "        0.10100233, 0.09746659, 0.09891252, 0.10050226, 0.10088906],\n",
       "       [0.09964296, 0.09998277, 0.09989744, 0.10047433, 0.10058792,\n",
       "        0.10179031, 0.09823333, 0.09869494, 0.10066029, 0.10003572],\n",
       "       [0.0986354 , 0.09988082, 0.10045291, 0.10099037, 0.10155249,\n",
       "        0.10093839, 0.09781693, 0.09908382, 0.1006316 , 0.10001726]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming the image preprocessing involves normalization and maybe some distortion, \n",
    "# we will just simulate this with a function that 'processes' images by a simple normalization for now.\n",
    "def preprocess_images(images):\n",
    "    # Normalize image data to 0-1\n",
    "    images_normalized = images / 255.0\n",
    "    return images_normalized\n",
    "\n",
    "# A simple DNN structure for simulation purposes\n",
    "class SimpleDNN:\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        # Simulate a simple neural network with random weights\n",
    "        self.weights = np.random.rand(input_shape, num_classes)\n",
    "    \n",
    "    def predict(self, image):\n",
    "        # Perform a simple matrix multiplication and softmax to simulate prediction\n",
    "        logits = np.dot(image, self.weights)\n",
    "        return np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "\n",
    "# Function to create and train a Multi-Column DNN\n",
    "def train_mcdnn(num_columns, input_shape, num_classes, images, labels):\n",
    "    # Create a list of DNNs\n",
    "    dnns = [SimpleDNN(input_shape, num_classes) for _ in range(num_columns)]\n",
    "    \n",
    "    # Simulate training and averaging predictions\n",
    "    predictions = np.zeros((len(images), num_classes))\n",
    "    for dnn in dnns:\n",
    "        # There is no actual training going on; we simulate this by just predicting with untrained networks\n",
    "        preds = dnn.predict(images)\n",
    "        predictions += preds\n",
    "        \n",
    "    # Average the predictions from each column\n",
    "    predictions /= num_columns\n",
    "    return predictions\n",
    "\n",
    "# Example usage\n",
    "num_classes = 10  # Just as an example, say we have 10 classes\n",
    "num_columns = 3   # Number of columns in the MCDNN\n",
    "input_shape = 784 # Example input shape (28x28 images flattened)\n",
    "\n",
    "# Simulate some data (e.g., MNIST)\n",
    "np.random.seed(0) # For reproducibility\n",
    "images = np.random.rand(100, input_shape) # 100 random images\n",
    "labels = np.random.randint(0, num_classes, 100) # 100 random labels\n",
    "\n",
    "# Preprocess the images\n",
    "processed_images = preprocess_images(images)\n",
    "\n",
    "# Train the MCDNN\n",
    "predictions = train_mcdnn(num_columns, input_shape, num_classes, processed_images, labels)\n",
    "\n",
    "# The predictions are now in `predictions` and we would typically calculate accuracy or other metrics here\n",
    "# However, since we have simulated data and a non-trained model, the accuracy would not be meaningful\n",
    "predictions[:5]  # Show the first 5 predictions for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3e46dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:37<00:00, 267686.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 42758804.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:13<00:00, 124436.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1217208.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 4608]' is invalid for input of size 346112",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a323ce569395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Clear gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a323ce569395>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mcolumn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0maveraged_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a323ce569395>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mcolumn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0maveraged_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a323ce569395>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# ... More layers if needed ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 4608]' is invalid for input of size 346112"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load and preprocess MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "class CNNColumn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNColumn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)  # Adding padding to maintain the size\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)  # Define conv2 with appropriate in/out channels\n",
    "        # Adjust the linear layer to match the output of the conv/pool layers\n",
    "        self.fc = nn.Linear(7 * 7 * 64, 10)  # Assuming the output is 7x7 after pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Adjust the view to match the fc layer input\n",
    "        x = x.view(-1, 7 * 7 * 64)  # Match the dimension with the fc layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class MCDNN(nn.Module):\n",
    "    def __init__(self, num_columns):\n",
    "        super(MCDNN, self).__init__()\n",
    "        self.columns = nn.ModuleList([CNNColumn() for _ in range(num_columns)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        column_outputs = [column(x) for column in self.columns]\n",
    "        averaged_output = torch.mean(torch.stack(column_outputs), dim=0)\n",
    "        return averaged_output\n",
    "\n",
    "# Instantiation, Training, Evaluation (Example Structure)\n",
    "num_columns = 5\n",
    "model = MCDNN(num_columns)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training and Evaluation\n",
    "num_epochs = 10  # Adjust as needed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if possible\n",
    "\n",
    "model.to(device)  # Move the model to the device\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            test_loss += loss_fn(outputs, labels).item()\n",
    "            test_acc += (outputs.argmax(dim=1) == labels).float().sum().item()\n",
    "\n",
    "    test_loss /= len(testloader)\n",
    "    test_acc /= len(testloader.dataset)\n",
    "    print(f\"Epoch {epoch+1}, Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd183d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the CNN architecture (similar to AlexNet)\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):  # CIFAR-10 has 10 classes\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# CIFAR-10 loading and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Resize images to size used by AlexNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Initialize the network\n",
    "net = AlexNet(num_classes=10)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save the trained model\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c2432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define a simple neural network with dropout\n",
    "class SimpleNetWithDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNetWithDropout, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(32 * 32 * 3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5)  # 50% probability of dropping out each neuron\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5)  # 50% probability of dropping out each neuron\n",
    "        )\n",
    "        self.layer3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the image\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Transform and load the CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize the network\n",
    "net = SimpleNetWithDropout()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradient buffers\n",
    "\n",
    "        outputs = net(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:  # Print every 200 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 200}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save the trained model\n",
    "PATH = './cifar_net_with_dropout.pth'\n",
    "torch.save(net.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1cbf34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
