{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d948307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.4255889012618836, Validation Loss: 3.6322504806110802\n",
      "Epoch 10, Loss: 1.1645221750168773, Validation Loss: 1.1594517615075772\n",
      "Epoch 20, Loss: 0.6103560517233885, Validation Loss: 0.5713222504802289\n",
      "Epoch 30, Loss: 0.4908288921997599, Validation Loss: 0.4408921076575615\n",
      "Epoch 40, Loss: 0.4393105248491456, Validation Loss: 0.3839297998093568\n",
      "Epoch 50, Loss: 0.408379673081413, Validation Loss: 0.3496043182630058\n",
      "Epoch 60, Loss: 0.38663484727079184, Validation Loss: 0.32551455633307413\n",
      "Epoch 70, Loss: 0.3699128518480143, Validation Loss: 0.30711262876999845\n",
      "Epoch 80, Loss: 0.35628993172112194, Validation Loss: 0.2922857274505119\n",
      "Epoch 90, Loss: 0.3447402520864707, Validation Loss: 0.27989548128599806\n",
      "Validation accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to perform softmax\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z))\n",
    "    return exp_z / exp_z.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Function for forward propagation in a single-layer neural network\n",
    "def forward_prop(X, W, b):\n",
    "    z = np.dot(X, W) + b\n",
    "    return softmax(z)\n",
    "\n",
    "# Function to compute the loss using negative log likelihood\n",
    "def compute_loss(y, y_hat):\n",
    "    # Using a small epsilon to avoid log(0)\n",
    "    epsilon = 1e-15\n",
    "    return -np.mean(np.log(y_hat[np.arange(len(y_hat)), y] + epsilon))\n",
    "\n",
    "# Gradient of the loss with respect to z\n",
    "def loss_gradient(y, y_hat):\n",
    "    gradients = y_hat.copy()\n",
    "    gradients[np.arange(len(y)), y] -= 1\n",
    "    return gradients / len(y)\n",
    "\n",
    "# Function to predict classes for given inputs\n",
    "def predict(X, W, b):\n",
    "    y_hat = forward_prop(X, W, b)\n",
    "    return np.argmax(y_hat, axis=1)\n",
    "\n",
    "# Training function for the single-layer neural network\n",
    "def train(X_train, y_train, X_val, y_val, epochs, learning_rate):\n",
    "    # Initialize weights and biases\n",
    "    W = np.random.randn(X_train.shape[1], len(np.unique(y_train)))\n",
    "    b = np.zeros((1, len(np.unique(y_train))))\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        # Forward propagation\n",
    "        y_hat_train = forward_prop(X_train, W, b)\n",
    "        y_hat_val = forward_prop(X_val, W, b)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = compute_loss(y_train, y_hat_train)\n",
    "        val_loss = compute_loss(y_val, y_hat_val)\n",
    "\n",
    "        # Backward propagation\n",
    "        gradients = loss_gradient(y_train, y_hat_train)\n",
    "        W -= learning_rate * np.dot(X_train.T, gradients)\n",
    "        b -= learning_rate * np.sum(gradients, axis=0, keepdims=True)\n",
    "\n",
    "        # Print loss every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss}, Validation Loss: {val_loss}')\n",
    "\n",
    "    return W, b\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Set hyperparameters\n",
    "epochs = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Train the model\n",
    "W, b = train(X_train_scaled, y_train, X_val_scaled, y_val, epochs, learning_rate)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = predict(X_val_scaled, W, b)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Validation accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfadaab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
